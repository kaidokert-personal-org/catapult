{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "09a6fb03_618306a1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 5
      },
      "lineNbr": 0,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2022-09-09T21:49:01Z",
      "side": 1,
      "message": "I think that as currently implemented, the GPU tests can actually end up in a state where we retry tests that are marked with Failure if there\u0027s also an overlapping RetryOnFailure expectation, which we don\u0027t want (it won\u0027t break anything, but will end up wasting resources)\n\nWe check whether we should retry on failure here https://source.chromium.org/chromium/chromium/src/+/main:content/test/gpu/gpu_tests/gpu_integration_test.py;l\u003d433?q\u003dgpu_integration_test, and that value comes from the expectation\u0027s `should_retry_on_failure` property https://source.chromium.org/chromium/chromium/src/+/main:third_party/catapult/telemetry/telemetry/testing/serially_executed_browser_test_case.py;l\u003d232?q\u003dgetexpectationsfortest\n\nWe shouldn\u0027t be retrying on failure if the test is expected to fail, but I\u0027m not sure off-hand whether we\u0027d want to handle that case in the GPU code or here...",
      "revId": "5fd865d8f35994d8502b640c26ab689a145c0625",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c0ed69d4_0310774f",
        "filename": "third_party/typ/typ/expectations_parser.py",
        "patchSetId": 5
      },
      "lineNbr": 585,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2022-09-09T21:49:01Z",
      "side": 1,
      "message": "Nit: typo",
      "range": {
        "startLine": 585,
        "startChar": 10,
        "endLine": 585,
        "endChar": 19
      },
      "revId": "5fd865d8f35994d8502b640c26ab689a145c0625",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}
{
  "comments": [
    {
      "key": {
        "uuid": "733db78d_c65d54f6",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 22,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T18:30:55Z",
      "side": 1,
      "message": "THis is nice, but it\u0027s a bit sad that it isn\u0027t better.",
      "range": {
        "startLine": 20,
        "startChar": 37,
        "endLine": 22,
        "endChar": 12
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a501d9e4_d95d629f",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 12,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T18:30:55Z",
      "side": 1,
      "message": "ah, I realized that you could just be using a non-blocking subprocess call, and then you won\u0027t need threading at all. I think it would be simpler.\n\nprocesses \u003d []\nfor binary_path in symbol_binaries:\n  processes.append(subprocess.Popen(blah blah blah))\nfor process in processes:\n  output, error \u003d process.communicate()\n  returncode \u003d process.returncode\n  if returncode:\n    logging.error(blah blah)\n\nNote that communicate buffers the data read in memory, so if breakpad generates a ton of output it could hang the program, but I think that subprocess.check_output does the same thing.",
      "range": {
        "startLine": 12,
        "startChar": 7,
        "endLine": 12,
        "endChar": 16
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "5639081f_37e1eadf",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 12,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T20:57:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "a501d9e4_d95d629f",
      "range": {
        "startLine": 12,
        "startChar": 7,
        "endLine": 12,
        "endChar": 16
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "a151fac8_02dca7de",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 107,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T18:30:55Z",
      "side": 1,
      "message": "I\u0027m concerned that this change could leak into the rest of the program. Should we reset the limit after this function completes? Alternatively, do we really need to do this? Maybe you could add comments explaining why this is necessary.",
      "range": {
        "startLine": 107,
        "startChar": 4,
        "endLine": 107,
        "endChar": 22
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "991b14ea_24f6c8d4",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 107,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T20:57:39Z",
      "side": 1,
      "message": "Added a comment better explaining why this is necessary.\n\nIt will technically leak without being reset, but I don\u0027t see any way it could cause issues - literally all it\u0027s doing is increasing the soft cap on open file handles for the process. This change is limited to the current process, so we aren\u0027t leaking it outside of the test.\n\nWe do need this, at least temporarily, as I was running into Mac\u0027s default soft cap of 256 file handles when running locally. Telemetry already has a number of handles open, and each subprocess opens several more for piping data.",
      "parentUuid": "a151fac8_02dca7de",
      "range": {
        "startLine": 107,
        "startChar": 4,
        "endLine": 107,
        "endChar": 22
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "86a3ecb1_a1c0faab",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 107,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T21:28:15Z",
      "side": 1,
      "message": "What happens when you run into the cap?\n\nHow many processes are you opening?\n\nI\u0027m wondering if we are getting seriously slowed down by all the subprocesses that we are spawning. Sometimes just starting up a new subprocess is very slow. I wonder if we would be better off if we instead tried importing https://cs.chromium.org/chromium/src/components/crash/content/tools/generate_breakpad_symbols.py annd directly calling its functions as a library (within a multiprocessing pool that we make have as many processes in it as we have logical CPUs)\n\nOr otherwise we could make a new version of generate_breakpad_symbols that took multiple input binaries and handled them efficiently.\n\nEither solution would prevent us needing to change these system limits, and I wonder if they could additionally improve our runtime further: 360 seconds is still pretty slow.",
      "parentUuid": "991b14ea_24f6c8d4",
      "range": {
        "startLine": 107,
        "startChar": 4,
        "endLine": 107,
        "endChar": 22
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "6ffca926_1937a448",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 107,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T22:05:32Z",
      "side": 1,
      "message": "The call to subprocess throws an exception and doesn\u0027t run the given command. In the original patchset, it ended up being non-fatal since it was in a separate thread and it happened to occur for binaries we didn\u0027t actually need data from, but there\u0027s no guarantee that will work out so well all the time.\n\nHitting the cap would be fatal in the current version since all the subprocesses are started from the main thread.\n\nLocally, I was dumping symbols for 281 binaries, so I was starting that many subprocesses. While starting a subprocess isn\u0027t super fast, I don\u0027t think it\u0027s a very large factor when determining runtime in this case. When I was working on this, I had debug logging in place each time it started a new process. That occurred quite quickly, and the remaining time was waiting for those processes to actually finish.\n\nUsing a pool instead of throwing everything at the CPU at once might provide a benefit, but I think it\u0027s going to largely depend on how much CPU time generate_breakpad_symbols takes compared to how much disk I/O it has to do. If it\u0027s spending a lot of time reading from disk, we might end up underutilizing the CPU and actually work slower.\n\nIt\u0027s easy enough to try that out locally, so I\u0027ll do that and report back on the results. One thing to note, though, is that I\u0027m not aware of a way to get the logical core count in Python - the one time I\u0027ve had to get core counts before, I could only find out the physical core count and no way to determine whether the CPU supported SMT (i.e. Hyperthreading on Intel CPUs).",
      "parentUuid": "86a3ecb1_a1c0faab",
      "range": {
        "startLine": 107,
        "startChar": 4,
        "endLine": 107,
        "endChar": 22
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "e1e525ef_9b7d2a97",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 107,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T22:08:09Z",
      "side": 1,
      "message": "Scratch that last note. Trying it out, looks like multiprocessing.cpu_count() returns the number of logical cores, so it should work.",
      "parentUuid": "6ffca926_1937a448",
      "range": {
        "startLine": 107,
        "startChar": 4,
        "endLine": 107,
        "endChar": 22
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4f2e6cfc_b1033bf3",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 107,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T22:09:16Z",
      "side": 1,
      "message": "Sounds good. Note that I have a vague recollection of multiprocessing.cpu_count() on working on certain platforms.",
      "parentUuid": "e1e525ef_9b7d2a97",
      "range": {
        "startLine": 107,
        "startChar": 4,
        "endLine": 107,
        "endChar": 22
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ce7f886e_16056a9e",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 130,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T18:30:55Z",
      "side": 1,
      "message": "I think I weakly prefer just printing out the list. The reason is that sometimes command components have whitespace in them, so the command stops being executable if you print it this way.",
      "range": {
        "startLine": 130,
        "startChar": 50,
        "endLine": 130,
        "endChar": 65
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "d8cac1a7_d013b6ca",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 130,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T20:57:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "ce7f886e_16056a9e",
      "range": {
        "startLine": 130,
        "startChar": 50,
        "endLine": 130,
        "endChar": 65
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "98229fc2_bae64c15",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 133,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T18:30:55Z",
      "side": 1,
      "message": "I think this thread is a SubprocessManagerThread. It starts a subprocess and watches it until it completes and then reports back on its status. I think \"Manager\" is the right word for that.",
      "range": {
        "startLine": 133,
        "startChar": 6,
        "endLine": 133,
        "endChar": 23
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3048d299_0a10143e",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 133,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T20:57:39Z",
      "side": 1,
      "message": "N/A since I switched to Popen.",
      "parentUuid": "98229fc2_bae64c15",
      "range": {
        "startLine": 133,
        "startChar": 6,
        "endLine": 133,
        "endChar": 23
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0ea8595d_1c5ced41",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 151,
      "author": {
        "id": 1149061
      },
      "writtenOn": "2020-01-08T18:30:55Z",
      "side": 1,
      "message": "This just looks like extra work to me. why not just do\n\nself.cmd \u003d cmd\nself.output \u003d output\nself.failed \u003d False\n\nLater on if we need to turn these into properties we can do that then.",
      "range": {
        "startLine": 137,
        "startChar": 1,
        "endLine": 151,
        "endChar": 20
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "12b05076_539fad94",
        "filename": "telemetry/telemetry/internal/backends/chrome/minidump_symbolizer.py",
        "patchSetId": 1
      },
      "lineNbr": 151,
      "author": {
        "id": 1163549
      },
      "writtenOn": "2020-01-08T20:57:39Z",
      "side": 1,
      "message": "N/A.",
      "parentUuid": "0ea8595d_1c5ced41",
      "range": {
        "startLine": 137,
        "startChar": 1,
        "endLine": 151,
        "endChar": 20
      },
      "revId": "357837c09a3fe2c1216afffae33d5610f9d70923",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}
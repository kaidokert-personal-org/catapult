{
  "comments": [
    {
      "key": {
        "uuid": "5a946b42_c2bb95a1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-16T06:03:05Z",
      "side": 1,
      "message": "LGTM\n\nLet\u0027s wait to land this when we\u0027ve started up the regular deletion process.\n\nCC\u0027ing Andrew who\u0027s the most knowledgeable person on the team when it comes to defining Cloud Scheduler invoked Dataflow template jobs.\n\nAndrew, let\u0027s sync on crafting the GQL queries for regularly deleting the entities this would be producing, and set up the appropriate deletion job(s).",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f459a663_05b1d36e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1284623
      },
      "writtenOn": "2020-09-21T06:03:35Z",
      "side": 1,
      "message": "So this looks a bit frustrating.  At first it seems like this is easy: there\u0027s a Google-provided Dataflow template to perform batch deletions on the result of a GQL query, and it\u0027s straightforward to schedule that to run daily or hourly or whatever via Cloud Scheduler.\n\nBut there\u0027s one piece missing: GQL has no CURRENT_DATETIME function equivalent!  So there\u0027s no way I can see to write a query relative to the current time, just a hard-coded literal time.  So we can\u0027t simply rely on timestamps to query for expired tokens.\n\nWe can could easily enough query by state, e.g.:\n\n  SELECT __key__ FROM `Token` WHERE state IN (2, 3);\n\nBut I\u0027m assuming this would be more aggressive than we want.  What\u0027s the intended lifetime of e.g. a COMPLETED token entity?\n\nWe should also consider the advice in https://cloud.google.com/datastore/docs/best-practices#deletions, which suggests that naive solutions may be unwise.",
      "parentUuid": "5a946b42_c2bb95a1",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f0406f13_263e66ca",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-21T07:27:28Z",
      "side": 1,
      "message": "\u003e GQL has no CURRENT_DATETIME function equivalent!\n\nCan we take it as an input from Cloud Scheduler, something that can be provided when running the template?\n\n\u003e But I\u0027m assuming this would be more aggressive than we want.  What\u0027s the intended lifetime of e.g. a COMPLETED token entity?\n\nWe don\u0027t provide an SLO on that, but given the current expiration of 10m, it\u0027s not going to be very long. If we\u0027re running the deletion every 3 hours I\u0027m fine with that spread of delay (anywhere between 0 to 3 hours). Even if it\u0027s a 24H delay I suspect we can live with that.\n\nThe only real concern for us is the storage cost. If we wait too long, we\u0027ll be generating a lot of tokens, and it will take longer to cleanup the tokens too.",
      "parentUuid": "f459a663_05b1d36e",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "9e7d0db3_f565ba79",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1284623
      },
      "writtenOn": "2020-09-21T07:41:23Z",
      "side": 1,
      "message": "\u003e \u003e GQL has no CURRENT_DATETIME function equivalent!\n\u003e \n\u003e Can we take it as an input from Cloud Scheduler, something that can be provided when running the template?\n\nCloud Scheduler doesn\u0027t have any facility for that that I can find.  My custom dataflow jobs avoided this by having parameters that default to the current date.\n\n\u003e \u003e But I\u0027m assuming this would be more aggressive than we want.  What\u0027s the intended lifetime of e.g. a COMPLETED token entity?\n\u003e \n\u003e We don\u0027t provide an SLO on that, but given the current expiration of 10m, it\u0027s not going to be very long. If we\u0027re running the deletion every 3 hours I\u0027m fine with that spread of delay (anywhere between 0 to 3 hours). Even if it\u0027s a 24H delay I suspect we can live with that.\n\nIf literally 0 is acceptable then we don\u0027t need the COMPLETED or FAILED states, we can just delete those entities straight away :)\n \n\u003e The only real concern for us is the storage cost. If we wait too long, we\u0027ll be generating a lot of tokens, and it will take longer to cleanup the tokens too.\n\nYep, that\u0027d be a painful spiral to be in.",
      "parentUuid": "f0406f13_263e66ca",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "36b23164_9cee7aaa",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-21T07:49:12Z",
      "side": 1,
      "message": "\u003e \u003e \u003e GQL has no CURRENT_DATETIME function equivalent!\n\u003e \u003e \n\u003e \u003e Can we take it as an input from Cloud Scheduler, something that can be provided when running the template?\n\u003e \n\u003e Cloud Scheduler doesn\u0027t have any facility for that that I can find.  My custom dataflow jobs avoided this by having parameters that default to the current date.\n\u003e\n\nYikes. Yeah I spent a few minutes trying to look that up but it seems pretty simple by design.\n \n\u003e \u003e \u003e But I\u0027m assuming this would be more aggressive than we want.  What\u0027s the intended lifetime of e.g. a COMPLETED token entity?\n\u003e \u003e \n\u003e \u003e We don\u0027t provide an SLO on that, but given the current expiration of 10m, it\u0027s not going to be very long. If we\u0027re running the deletion every 3 hours I\u0027m fine with that spread of delay (anywhere between 0 to 3 hours). Even if it\u0027s a 24H delay I suspect we can live with that.\n\u003e \n\u003e If literally 0 is acceptable then we don\u0027t need the COMPLETED or FAILED states, we can just delete those entities straight away :)\n\u003e  \n\nThere\u0027s a difference between being able to observe that the token was completed and not ever being able to observe it. üòä\n\nSo let me refine that -- at least 10 minutes to ~3 hours. üòÜ\n\n\u003e \u003e The only real concern for us is the storage cost. If we wait too long, we\u0027ll be generating a lot of tokens, and it will take longer to cleanup the tokens too.\n\u003e \n\u003e Yep, that\u0027d be a painful spiral to be in.\n\nIndeed. The other option here is to have a streaming dataflow job that will perform the deletion, and triggering a pub/sub message every hour or some such frequency. That way we control the deletion and can trigger it as often/sparsely as we want.",
      "parentUuid": "9e7d0db3_f565ba79",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "68fe718b_1ac668d1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1284623
      },
      "writtenOn": "2020-09-21T08:24:25Z",
      "side": 1,
      "message": "It doesn\u0027t even need to be a streaming dataflow job, a regular batch job triggered via cloud scheduler would still give us sufficient flexibility.  Although it may as well be streaming I guess.\n\nAnother solution might be to do more work in appengine tasks to update these entities in a way that a fixed GQL query could find, but that seems unlikely it would be simpler or more robust.\n\nI\u0027ll take a look at making this dataflow job tomorrow.",
      "parentUuid": "36b23164_9cee7aaa",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "7bd84e70_8d5c4f59",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1284623
      },
      "writtenOn": "2020-09-23T09:15:29Z",
      "side": 1,
      "message": "Update: after writing this simple custom job I\u0027ve belatedly realised we can probably do it with the standard bulk delete job template!  The trick is we can provide a Javascript UDF to implement the necessary filtering.  See the javascript* options: https://cloud.google.com/dataflow/docs/guides/templates/provided-utilities#template-parameters_2\n\nSo the job invocation should be pretty straightforward.  The GQL needs to include the update_time in the projection, and then the UDF can filter it based on that ‚Äî assuming that whatever the JS runtime environment is lets us get the current time via ‚Äúnew Date()‚Äù.  I\u0027ve uploaded a simple JS file to gs://chromeperf-dataflow/gc-tokens-udf.js that ought to do this.\n\nI can\u0027t really test this until we have some live Token entities, though.  So let\u0027s land this.  If the standard bulk delete + UDF fails, I\u0027ll deploy the custom delete job instead.",
      "parentUuid": "68fe718b_1ac668d1",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "369b1184_dcd5ad70",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-23T09:54:35Z",
      "side": 1,
      "message": "Ok, I\u0027m triggering submit.",
      "parentUuid": "7bd84e70_8d5c4f59",
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "ea0008a9_78e9f03f",
        "filename": "dashboard/dashboard/add_histograms.py",
        "patchSetId": 4
      },
      "lineNbr": 439,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-16T06:03:05Z",
      "side": 1,
      "message": "Do we want to update the upload token to include the error information too, instead of just raising this error now that we have a way of signalling failure?",
      "range": {
        "startLine": 438,
        "startChar": 6,
        "endLine": 439,
        "endChar": 57
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "a933038c_6709352b",
        "filename": "dashboard/dashboard/add_histograms.py",
        "patchSetId": 4
      },
      "lineNbr": 439,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-16T08:12:10Z",
      "side": 1,
      "message": "Yes, I think it\u0027s a good idea. I\u0027ll do it in another cl though. Now that I think about it, adding the error message to /uploads api should really be useful.",
      "parentUuid": "ea0008a9_78e9f03f",
      "range": {
        "startLine": 438,
        "startChar": 6,
        "endLine": 439,
        "endChar": 57
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "7997450f_940bf452",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 14,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-16T06:03:05Z",
      "side": 1,
      "message": "nit: This might be easier to read if this was in the active voice.\n\n10 minutes should be enough for keeping the data in memory because processing histograms takes 3.5 minutes in the 90th percentile.",
      "range": {
        "startLine": 13,
        "startChar": 2,
        "endLine": 14,
        "endChar": 79
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "7d62a8fd_9ff91416",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 14,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-17T14:22:20Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "7997450f_940bf452",
      "range": {
        "startLine": 13,
        "startChar": 2,
        "endLine": 14,
        "endChar": 79
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "50a517d0_26f996eb",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 15,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-16T06:03:05Z",
      "side": 1,
      "message": "I\u0027m not sure this is true. We cannot predict how many uploads come in from the service\u0027s perspective because that\u0027s controlled by our users/uploaders.",
      "range": {
        "startLine": 15,
        "startChar": 2,
        "endLine": 15,
        "endChar": 76
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0d60988d_3b2d4962",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 15,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-17T14:22:20Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "50a517d0_26f996eb",
      "range": {
        "startLine": 15,
        "startChar": 2,
        "endLine": 15,
        "endChar": 76
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "cdabecab_28328faa",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 19,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-16T06:03:05Z",
      "side": 1,
      "message": "This might be true, but I\u0027m not sure putting this in the documentation on my we\u0027re picking 10 minutes is the right approach.",
      "range": {
        "startLine": 16,
        "startChar": 2,
        "endLine": 19,
        "endChar": 19
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "53cb719c_8c56d832",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 19,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-16T08:12:10Z",
      "side": 1,
      "message": "Hm. Should we keep 10 minutes timeout at all?\nShould the comment be just \"10 minutes should be enough for keeping the data in memory because processing histograms takes 3.5 minutes in the 90th percentile.\"? I have added more thoughts because Mirko has asked to expand it.",
      "parentUuid": "cdabecab_28328faa",
      "range": {
        "startLine": 16,
        "startChar": 2,
        "endLine": 19,
        "endChar": 19
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "268b05b9_98ab20a1",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 19,
      "author": {
        "id": 1178490
      },
      "writtenOn": "2020-09-16T08:20:05Z",
      "side": 1,
      "message": "Yes, my bad. üòä\n\nI think it needs to be documented somewhere for future reference though.",
      "parentUuid": "53cb719c_8c56d832",
      "range": {
        "startLine": 16,
        "startChar": 2,
        "endLine": 19,
        "endChar": 19
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "cd6b0c60_21fd9916",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 4
      },
      "lineNbr": 19,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-17T14:22:20Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "268b05b9_98ab20a1",
      "range": {
        "startLine": 16,
        "startChar": 2,
        "endLine": 19,
        "endChar": 19
      },
      "revId": "0dd70fd704da94c21c587de6fbc250e57248e15b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba",
      "unresolved": false
    }
  ]
}
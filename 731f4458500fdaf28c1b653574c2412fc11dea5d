{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "212a0e25_4b87fc04",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 3
      },
      "lineNbr": 146,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-09-24T23:12:45Z",
      "side": 1,
      "message": "Note that this query is not transactionally safe, and because the Measurement kind turns into a separate entity group you\u0027re likely to get stale (eventually consistent) information.\n\nHave you considered using transactions instead?",
      "range": {
        "startLine": 144,
        "startChar": 11,
        "endLine": 146,
        "endChar": 71
      },
      "revId": "731f4458500fdaf28c1b653574c2412fc11dea5d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "481102f1_52986930",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 3
      },
      "lineNbr": 146,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-09-25T08:12:34Z",
      "side": 1,
      "message": "I worry, wouldn\u0027t transaction create the same bottleneck as entity group does?",
      "parentUuid": "212a0e25_4b87fc04",
      "range": {
        "startLine": 144,
        "startChar": 11,
        "endLine": 146,
        "endChar": 71
      },
      "revId": "731f4458500fdaf28c1b653574c2412fc11dea5d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "dc27a34c_c3e6b599",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 3
      },
      "lineNbr": 146,
      "author": {
        "id": 1284623
      },
      "writtenOn": "2020-09-30T06:26:39Z",
      "side": 1,
      "message": "I think a transaction will help if you\u0027re writing to the same entity group more than once, because then the whole transaction will count as one write rather than several.\n\nI believe the relevant docs are https://cloud.google.com/datastore/docs/cloud-datastore-best-practices#entities and https://cloud.google.com/datastore/docs/concepts/structuring_for_strong_consistency#entity_group_limitations_on_transactions.\n\nI\u0027m not super confident about this, but I think it makes sense to try using transactions as first step here, because if it works it will be safe.  Whereas using separate entity groups definitely adds consistency problems.",
      "parentUuid": "481102f1_52986930",
      "range": {
        "startLine": 144,
        "startChar": 11,
        "endLine": 146,
        "endChar": 71
      },
      "revId": "731f4458500fdaf28c1b653574c2412fc11dea5d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "fd4aa388_1fffa20c",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 3
      },
      "lineNbr": 146,
      "author": {
        "id": 1428512
      },
      "writtenOn": "2020-09-30T09:21:11Z",
      "side": 1,
      "message": "Hm, I actually don\u0027t see a good way to use transactions here. Can you give me a hint?\n\nIf the transaction is limited to 25 entity groups per query - we can\u0027t perform \"Measurement.query(ndb.AND(Measurement.test_path \u003d\u003d test_path, Measurement.token \u003d\u003d ndb.Key(\u0027Token\u0027, token_id))).get()\" query unless we make token and nested measurements one entity group again. Which would get us back to the \"too much contention\" problem.\n\nI think we could split all token\u0027s measurements into a 25 separate entity groups, but it seems like an over-complication. And there is no guarantee that it won\u0027t cause \"too much contention\" (sometimes token can have 1000+ measurements).\n\nActually I don\u0027t see a big problem in a stale data here. There is no way we would miss some measurement. Since we add all measurements at /add_histogram and then access them at /add_histogram_queue. We only could get stale state or error_message information, which can\u0027t affect behavior of the system. In worst case scenario we will get misleading logs at \"_LogStateChanged\". But I can just change logs, so it won\u0027t be a problem. And add a few clarification comments.\n\nDoes it make sense? Or am I missing something?",
      "parentUuid": "dc27a34c_c3e6b599",
      "range": {
        "startLine": 144,
        "startChar": 11,
        "endLine": 146,
        "endChar": 71
      },
      "revId": "731f4458500fdaf28c1b653574c2412fc11dea5d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b82775bc_d1794d69",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 3
      },
      "lineNbr": 146,
      "author": {
        "id": 1327821
      },
      "writtenOn": "2020-10-06T02:18:57Z",
      "side": 1,
      "message": "\u003e Hm, I actually don\u0027t see a good way to use transactions here. Can you give me a hint?\n\nI can try. ðŸ˜Š\n\n\u003e \n\u003e If the transaction is limited to 25 entity groups per query - we can\u0027t perform \"Measurement.query(ndb.AND(Measurement.test_path \u003d\u003d test_path, Measurement.token \u003d\u003d ndb.Key(\u0027Token\u0027, token_id))).get()\" query unless we make token and nested measurements one entity group again. Which would get us back to the \"too much contention\" problem.\n\u003e \n\nNo, in a transaction, you avoid the \"too much contention\" problem by marking transactions as as read-only, and updates to the same entity groups would be lined up accordingly. This will require that all your queries and updates are wrapped in transactions instead for this entity group.\n\n\u003e I think we could split all token\u0027s measurements into a 25 separate entity groups, but it seems like an over-complication. And there is no guarantee that it won\u0027t cause \"too much contention\" (sometimes token can have 1000+ measurements).\n\u003e \n\nThat would be the wrong solution. ðŸ˜Š\n\nKeeping it in a single entity group (Measurement nested under Token) and using transactions should avoid the \"too much contention\" problem especially if you\u0027re using the ndb transaction wrapper.\n\n\u003e Actually I don\u0027t see a big problem in a stale data here. There is no way we would miss some measurement. Since we add all measurements at /add_histogram and then access them at /add_histogram_queue. We only could get stale state or error_message information, which can\u0027t affect behavior of the system. In worst case scenario we will get misleading logs at \"_LogStateChanged\". But I can just change logs, so it won\u0027t be a problem. And add a few clarification comments.\n\u003e \n\u003e Does it make sense? Or am I missing something?\n\nWhen creating the Measurement entities as a batch, you can do that inside a single transaction so it counts as one write (as Andrew pointed out), and when you do read-only transactions then the queries inside the transaction count as one read. That\u0027s how you avoid the \"too much contention\" issue, at the cost of potential retries and delays.\n\nNote that in transactions, only ancestor queries can be done, which is why nesting Measurement under Token is required for that to happen.\n\nDoes that help?",
      "parentUuid": "fd4aa388_1fffa20c",
      "range": {
        "startLine": 144,
        "startChar": 11,
        "endLine": 146,
        "endChar": 71
      },
      "revId": "731f4458500fdaf28c1b653574c2412fc11dea5d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "07246124_cc68b1df",
        "filename": "dashboard/dashboard/models/upload_completion_token.py",
        "patchSetId": 3
      },
      "lineNbr": 146,
      "author": {
        "id": 1428517
      },
      "writtenOn": "2020-10-21T10:27:09Z",
      "side": 1,
      "message": "We have discussed it in person and agreed not to use transaction. Sometimes there are tokens that contains up to 3000 measurements. While we can put all creations into one batch, there is no way we can do the same with all updates. Taking into account 1 transaction per second limit for an entity group - there is no way we can fit it.",
      "parentUuid": "b82775bc_d1794d69",
      "range": {
        "startLine": 144,
        "startChar": 11,
        "endLine": 146,
        "endChar": 71
      },
      "revId": "731f4458500fdaf28c1b653574c2412fc11dea5d",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}